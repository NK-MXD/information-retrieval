# 我的Web搜索引擎说明

## 实验要求

本次作业我们要求实现⼀个系统的Web搜索引擎（主题不限），为用户提供查询服务和个性化推荐。

本次作业中需要包含以下几个部分:
+ 网页爬取;
+ 文本索引;
+ 链接分析;
+ 查询服务: 为用户提供站内查询、短语查询、通配查询、查询日志、网页快照等高级搜索功能;
+ 个性化查询: 不同用户提供不同的内容查询;
+ Web界面;
+ 个性化推荐;

## 实验进度

1. 网页爬取任务
   + [X] 11.23搭建Scrapy框架;
   + [X] 11.23配置环境;
   + [ ] 完善Scrapy框架中的内容;
   + [ ] 将爬取到的网页数据存入MongoDB数据库当中;


## 实验框架

![Pasted image 20221102153935](https://image-1305894911.cos.ap-beijing.myqcloud.com/Obsidian/202211111612007.png)

### 爬虫框架的搭建

#### 复习Scrapy框架的搭建

Scrapy中的数据流受引擎控制, 各组件的用途为:

![](https://image-1305894911.cos.ap-beijing.myqcloud.com/Obsidian/202211232231396.png)

#### 本程序搭建框架

1. items中爬取的数据:
   1. title字段;
   2. url字段;
   3. urlmd5字段; (注: 暂时不考虑)
   4. content内容字段;

2. spider中response的编写:
    难点: 断点续爬
    难点: 锚的定位(即定位到下一个url)

### 索引建立

#### 三维空间模型
Lucene

#### 概率模型
Lemur

